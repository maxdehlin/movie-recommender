{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794df80e",
   "metadata": {},
   "source": [
    "Movie Recommender System\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. import packages and data\n",
    "2. train hybrid model on MovieLens data\n",
    "\n",
    "    2a. Content-based for cold start\n",
    "\n",
    "    2b. Collaborative filtering afterwards\n",
    "    \n",
    "3. evaluate model\n",
    "4. deploy model using flask/etc.\n",
    "    4a. Api calls to collect user events\n",
    "    4b. Retrain model with new batch every night\n",
    "\n",
    "User Perspective:\n",
    "\n",
    "Simple website that requests an account signup. The user will input 10 movies and their ratings. When they watch movies they will update their profile. They will be provided with 10 recommended movies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a45c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386be67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "url = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@localhost:5432/movie_db\"\n",
    "engine = create_engine(url)\n",
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(\"SELECT 1\")).scalar())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01dda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "small = 'data/ml-latest-small'\n",
    "big = 'data/ml-32m'\n",
    "folder = big\n",
    "\n",
    "ratings = pd.read_csv(f'{folder}/ratings.csv')\n",
    "\n",
    "\n",
    "movies = pd.read_csv(f'{folder}/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f17a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a sparse utility matrix\n",
    "def create_X(df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: pandas dataframe containing 3 columns (userId, movieId, rating)\n",
    "    \n",
    "    Returns:\n",
    "        X: sparse matrix\n",
    "        user_mapper: dict that maps user id's to user indices\n",
    "        user_inv_mapper: dict that maps user indices to user id's\n",
    "        movie_mapper: dict that maps movie id's to movie indices\n",
    "        movie_inv_mapper: dict that maps movie indices to movie id's\n",
    "    \"\"\"\n",
    "    M = df['userId'].nunique()\n",
    "    N = df['movieId'].nunique()\n",
    "\n",
    "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
    "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
    "    \n",
    "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
    "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
    "    \n",
    "    user_index = [user_mapper[i] for i in df['userId']]\n",
    "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
    "\n",
    "    X = csr_matrix((df[\"rating\"], (user_index,item_index)), shape=(M,N))\n",
    "    \n",
    "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85603f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_X(ratings)\n",
    "movie_titles = dict(zip(movies['movieId'], movies['title']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621647f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# X is (n_users × n_items) csr_matrix already loaded.\n",
    "\n",
    "X_csc = X.tocsc()  # shape = (n_users, n_items)\n",
    "\n",
    "n_items = X_csc.shape[1]\n",
    "# supports[i] = set of user‐indices who rated item i\n",
    "supports = []\n",
    "for i in range(n_items):\n",
    "    # nonzero()[0] gives the row‐indices of nonzero entries in column i\n",
    "    users_who_rated_i = set(X_csc[:, i].nonzero()[0])\n",
    "    supports.append(users_who_rated_i)\n",
    "\n",
    "# fit NearestNeighbors on the (n_items × n_users) transpose:\n",
    "item_features = X_csc.T  # now shape = (n_items, n_users), still sparse\n",
    "\n",
    "K = 15\n",
    "nn = NearestNeighbors(\n",
    "    n_neighbors=K + 1,\n",
    "    metric=\"cosine\",\n",
    "    algorithm=\"brute\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "nn.fit(item_features)\n",
    "\n",
    "distances, indices = nn.kneighbors(item_features, return_distance=True)\n",
    "\n",
    "alpha = 10  # shrinkage parameter\n",
    "anchor_ids = []\n",
    "neighbor_ids = []\n",
    "raw_sims   = []\n",
    "co_counts  = []\n",
    "weighted_sims = []\n",
    "\n",
    "for i in range(n_items):\n",
    "    anchor_id = movie_inv_mapper[i]\n",
    "    for rank in range(1, K + 1):  # skip rank=0 (itself)\n",
    "        j = indices[i][rank]\n",
    "        neighbor_id = movie_inv_mapper[j]\n",
    "\n",
    "        raw_sim = 1.0 - distances[i][rank]\n",
    "\n",
    "        # set intersection for efficient co_count computation\n",
    "        co_cnt = len(supports[i] & supports[j])\n",
    "        shrink = co_cnt / (co_cnt + alpha)\n",
    "        w_sim = raw_sim * shrink\n",
    "\n",
    "        anchor_ids.append(int(anchor_id))\n",
    "        neighbor_ids.append(int(neighbor_id))\n",
    "        raw_sims.append(float(raw_sim))\n",
    "        co_counts.append(co_cnt)\n",
    "        weighted_sims.append(float(w_sim))\n",
    "\n",
    "# FORM (anchor_ids, neighbor_ids, raw_sims, co_counts, weighted_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9e3ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114\n",
      "<class 'float'>\n",
      "26553\n",
      "0.5745980425227315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(neighbor_ids[0])\n",
    "print(type(raw_sims[0]))\n",
    "print(co_counts[0])\n",
    "print(weighted_sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a34fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MovieSimilarity, Movie\n",
    "from db import SessionLocal\n",
    "\n",
    "def insert_movies():\n",
    "    session = SessionLocal()\n",
    "    batch = [\n",
    "        Movie(id=row.movieId, title=row.title, genres=row.genres)\n",
    "        for row in movies.itertuples()\n",
    "    ]\n",
    "    session.bulk_save_objects(batch)\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "def insert_all_similarities():\n",
    "    session = SessionLocal()\n",
    "    batch = []\n",
    "    # anchor_ids, neighbor_ids, raw_sims, co_counts, weighted_sims\n",
    "    for (a_id, n_id, r_sim, c_cnt, w_sim) in zip(\n",
    "        anchor_ids, neighbor_ids, raw_sims, co_counts, weighted_sims\n",
    "    ):\n",
    "        batch.append(\n",
    "            MovieSimilarity(\n",
    "                movie_id=a_id,\n",
    "                neighbor_id=n_id,\n",
    "                raw_sim=r_sim,\n",
    "                co_count=c_cnt,\n",
    "                weighted_sim=w_sim,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Bulk‐save\n",
    "    session.bulk_save_objects(batch)\n",
    "    session.commit()\n",
    "    session.close()\n",
    "insert_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c779dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_all_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a6fdf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<models.MovieSimilarity object at 0x4582a9d50>, <models.MovieSimilarity object at 0x4582a9dd0>, <models.MovieSimilarity object at 0x4582aa0d0>, <models.MovieSimilarity object at 0x4582ab4d0>, <models.MovieSimilarity object at 0x4582abd50>, <models.MovieSimilarity object at 0x4582ab2d0>, <models.MovieSimilarity object at 0x4582ab650>, <models.MovieSimilarity object at 0x4582abe50>, <models.MovieSimilarity object at 0x4582abbd0>, <models.MovieSimilarity object at 0x4582ab3d0>]\n",
      "movie_id=1, neighbor_id=3114, raw_sim=0.5748, co_count=26553, weighted_sim=0.5746\n",
      "movie_id=1, neighbor_id=260, raw_sim=0.5617, co_count=44291, weighted_sim=0.5616\n",
      "movie_id=1, neighbor_id=1270, raw_sim=0.5455, co_count=36826, weighted_sim=0.5454\n",
      "movie_id=1, neighbor_id=356, raw_sim=0.5416, co_count=47506, weighted_sim=0.5415\n",
      "movie_id=1, neighbor_id=480, raw_sim=0.5399, co_count=40580, weighted_sim=0.5398\n",
      "movie_id=1, neighbor_id=364, raw_sim=0.5367, co_count=32569, weighted_sim=0.5366\n",
      "movie_id=1, neighbor_id=1210, raw_sim=0.5343, co_count=37806, weighted_sim=0.5342\n",
      "movie_id=1, neighbor_id=780, raw_sim=0.5305, co_count=35843, weighted_sim=0.5304\n",
      "movie_id=1, neighbor_id=588, raw_sim=0.5266, co_count=31246, weighted_sim=0.5265\n",
      "movie_id=1, neighbor_id=4306, raw_sim=0.5144, co_count=32583, weighted_sim=0.5142\n"
     ]
    }
   ],
   "source": [
    "from db import SessionLocal\n",
    "from models import MovieSimilarity\n",
    "\n",
    "session = SessionLocal()\n",
    "\n",
    "# Query the first 10 rows\n",
    "examples = (\n",
    "    session.query(MovieSimilarity)\n",
    "           .limit(10)\n",
    "           .all()\n",
    ")\n",
    "print(examples)\n",
    "for row in examples:\n",
    "    print(\n",
    "        f\"movie_id={row.movie_id}, \"\n",
    "        f\"neighbor_id={row.neighbor_id}, \"\n",
    "        f\"raw_sim={row.raw_sim:.4f}, \"\n",
    "        f\"co_count={row.co_count}, \"\n",
    "        f\"weighted_sim={row.weighted_sim:.4f}\"\n",
    "    )\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea03f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with seed movies\n",
    "\n",
    "seed_movies = [(1, 5.0), (2, 3.5), (3, 5.0),(4, 2.5), (5, 4.0),\n",
    "               (6, 1.5),  (7, 1.0),  (8, 3.0),  (9, 2.5),  (10, 2.5),\n",
    "    (11, 2.0), (12, 1.5), (13, 5.0), (14, 1.5), (15, 4.0),\n",
    "    (16, 1.0), (17, 1.0), (18, 1.5), (19, 2.5), (20, 2.5),\n",
    "    (21, 5.0), (22, 2.5), (23, 2.5), (24, 3.0), (25, 3.0),\n",
    "    (26, 4.0), (27, 2.0), (28, 4.5), (29, 1.5), (30, 2.5),\n",
    "    (31, 4.5), (32, 3.5), (33, 2.0), (34, 1.5), (35, 1.0),\n",
    "    (36, 2.0), (37, 3.0), (38, 1.0), (39, 4.5), (40, 2.0),\n",
    "    (41, 3.0), (42, 3.5), (43, 3.0), (44, 1.5), (45, 1.5),\n",
    "    (46, 3.0), (47, 1.5), (48, 3.5), (49, 2.0), (50, 1.0),\n",
    "    (51, 2.5), (52, 1.5), (53, 3.5), (54, 1.5), (55, 3.0),\n",
    "    (57, 3.5), (58, 4.5), (59, 2.5), (60, 3.5),\n",
    "    (61, 1.5), (62, 3.0), (63, 3.5), (64, 1.0), (65, 3.0),\n",
    "    (66, 4.5), (67, 2.5), (68, 2.0), (69, 5.0), (70, 4.0),\n",
    "    (71, 2.5), (72, 1.0), (73, 1.0), (74, 4.0), (75, 3.5),\n",
    "    (76, 3.0), (77, 3.5), (78, 2.0), (79, 4.0), (80, 3.0),\n",
    "    (81, 2.0), (82, 4.5), (83, 5.0), (85, 2.0),\n",
    "    (86, 3.5), (87, 1.5), (88, 2.0), (89, 1.0), (90, 3.5),\n",
    "    (91, 2.5), (92, 4.5), (93, 4.0), (94, 4.5), (95, 2.0),\n",
    "    (96, 3.0), (97, 2.0), (98, 2.5), (99, 5.0), (100, 5.0),\n",
    "    (101, 3.0), (102, 4.0), (103, 4.0), (104, 3.5), (105, 2.5),]\n",
    "\n",
    "\n",
    "minimum_seed_count = 3\n",
    "# take all movies rated higher than 4 stars\n",
    "# if none, take top 3 movies\n",
    "def find_highly_rated_movies(seed_movies):\n",
    "    sorted_movies = sorted(seed_movies, key=lambda x: x[1], reverse=True)\n",
    "    output = []\n",
    "    for i in range(len(sorted_movies)):\n",
    "        movie = sorted_movies[i]\n",
    "        if movie[1] < 4.0 and len(output) > minimum_seed_count:\n",
    "            break\n",
    "        output.append(movie[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# import pickle\n",
    "# import time\n",
    "\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_X(ratings)\n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "\n",
    "# start = time.time()\n",
    "# svd = TruncatedSVD(n_components=20, n_iter=10)\n",
    "# Q = svd.fit_transform(X.T)\n",
    "# Q.shape\n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "\n",
    "# start = time.time()\n",
    "# S = cosine_similarity(Q) # similarity matrix\n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "\n",
    "# start = time.time()\n",
    "# # Save S to database\n",
    "# with open('database/similarity_matrix.pkl','wb') as f:\n",
    "#     pickle.dump(S, f)\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03736bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print('S', S)\n",
    "# movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
    "# movie_titles_inv = dict(zip(movies['title'], movies['movieId']))\n",
    "\n",
    "\n",
    "\n",
    "# movie = 673\n",
    "# title = movie_titles[movie]\n",
    "\n",
    "# similar_movies = neighbors.get(movie)[:10]\n",
    "# # movie_titles = [movie_titles[mov] for mov in similar_movies]\n",
    "# # print(f'Similar movies to {title}:', movie_titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e92f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# later: \n",
    "# with open('item_neighbors.pkl','rb') as f:\n",
    "#     neighbors = pickle.load(f)\n",
    "# then neighbors[movie_id] gives your k similar movies directly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
